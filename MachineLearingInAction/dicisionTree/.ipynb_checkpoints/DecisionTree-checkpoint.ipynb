{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet=[[1,1,'yes'],\n",
    "            [1,0,'no'],\n",
    "            [0,1,'no'],\n",
    "            [0,1,'no']]\n",
    "    labels=['no surfacing','flippers']\n",
    "    return dataSet,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算给定数据集的香农熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    numEntries=len(dataSet)\n",
    "    labelCounts={} # 创建标签字典\n",
    "    for featVec in dataSet:\n",
    "        currentLabel=featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel]=0 # 如果当前key不存在，则扩展字典将当前标签值加入字典\n",
    "        labelCounts[currentLabel]+=1\n",
    "    shannonEnt=0.0 # 默认香农熵为0.0\n",
    "    for key in labelCounts: # 计算香农熵\n",
    "        prob=float(labelCounts[key])/numEntries\n",
    "        shannonEnt-=prob* log(prob,2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet,axis,value):\n",
    "    retDataSet=[] # 最终处理完成的list对象\n",
    "    for reatVec in dataSet:\n",
    "        if featVec ==value:\n",
    "            reducedFeatVec=featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec) # 当我们按照某个特征划分数据集时，要将所有符合要求的元素抽取出来\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择最好的数据集划分方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures=len(dataSet[0])-1 # 特征数量值\n",
    "    baseEntropy=calcShannonEnt(dataSet) # 初始香农熵\n",
    "    bestInfoGain=0.0;bestFeature=-1\n",
    "    for i in range(numFeatures): # 对每个特征值做如下处理：\n",
    "        featList=[example[i] for example in dataSet]  # 获取每个特征值的全集\n",
    "        uniqueVals=set(featList) # 将每个特征值的全集处理成不重复的集合\n",
    "        newEntropy=0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet=splitDataSet(dataSet,i,value) # 按照特征值的每个取值，对数据集进行划分\n",
    "            prob=len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy+=prob*calcShannonEnt(subDataSet) # 计算香农熵\n",
    "        infoGain=baseEntropy-newEntropy\n",
    "        if(infoGain > bestInfoGain):\n",
    "            bestInfoGain=infoGain\n",
    "            bestFeature=i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 若数据集已经处理了所有的属性，但是类标签仍旧不唯一，此时选择概率最大的作为标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator as op\n",
    "def majorityCnt(classList):\n",
    "    calssCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in calssCount.keys(): classCount[vote]=0\n",
    "        classCount[vote] +=1\n",
    "    sortedClassCount=sorted(classCount.items(),key=op.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    classList=[example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0])==len(classList):  # 类别相同则停止继续划分\n",
    "        return classList[0]\n",
    "    if len(dataSet[0])==1:\n",
    "        return majorityCnt(classList) # 遍历完所有特征时返回出现次数最多的类别\n",
    "    bestFeat=chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel=labels[bestFeat]\n",
    "    myTree={bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues=[example[bestFeat] for example in dataSet]\n",
    "    uniqueVals=set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels=labels[:]\n",
    "        myTree[bestFeatLabel][value]=createTree(splitDataSet(dataSet,bestFeat,value),subLabels)\n",
    "    return myTree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
